{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBE Gender Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ebe_gender_data_file = \"\" # path_to_file\n",
    "df = pd.read_csv(ebe_gender_data_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['explicitGender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export $(cat .env | xargs) && env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to filter out the sentences that does not make any sense semantically and select those sentences that can be generalized for both genders. We check only the pair sentences (the sentences where the subject from natural sentences is replaced by opposing gender entity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(api_key=\"\") # place your key here\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "system_prompt = '''You are an assistant. Your job is to determine whether a given prompt Bangla is semantically correct and does not \n",
    "contradict nature of men. Respond with 1 for yes and 0 for no and provide no other extra answer.'''\n",
    "\n",
    "def sanitize_log_name(filename):\n",
    "    return filename.replace(\" \", \"_\").replace(\":\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "def create_message(text, pair):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.replace(\"\\n\", \" \")},\n",
    "        {\"role\": \"user\", \"content\": f\"Text: {pair}\"}\n",
    "    ]\n",
    "\n",
    "def validate_data(df):\n",
    "    count = 0\n",
    "\n",
    "    f = open(sanitize_log_name(f\"./logs/data_generation_{datetime.now()}.log\"), \"w\")\n",
    "    for index, row in df.iterrows():\n",
    "        if row['selected'] != -2:\n",
    "            continue\n",
    "        if row[\"explicitGender\"] != 'female':\n",
    "            continue\n",
    "        text = row[\"text\"]\n",
    "        pair = row['pair']\n",
    "        if len(pair.split()) < 6: \n",
    "            print(f\"Index: {index}, sentence: {pair}, content: {0} -> too short\")\n",
    "            f.write(f\"Index: {index}, sentence: {pair}, content: {0} -> too short\\n\")\n",
    "            df.at[index, 'selected'] = 0\n",
    "            continue\n",
    "        model_message = create_message(text, pair)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model_name, messages=model_message, temperature=0.1\n",
    "        )\n",
    "\n",
    "        content = completion.choices[0].message.content\n",
    "        print(f\"Index: {index}, sentence: {pair}, content: {content}\")\n",
    "        f.write(f\"Index: {index}, sentence: {pair}, content: {content}\\n\")\n",
    "        if content == \"0\" or content == \"no\":\n",
    "            df.at[index, 'selected'] = 0\n",
    "        elif content == \"1\" or content == \"yes\":\n",
    "            df.at[index, 'selected'] = 1\n",
    "        else:\n",
    "            df.at[index, 'selected'] = -1\n",
    "            print(f\"Error at index: {index}\")\n",
    "            f.write(f\"Error at index: {index}\\n\")\n",
    "\n",
    "        count += 1\n",
    "        if count == 2000:\n",
    "            break\n",
    "\n",
    "        if count % 20 == 0 and count > 1:\n",
    "            df.to_csv(\"./ebe_gender_data_selection.csv\", index=False) \n",
    "\n",
    "gender_ebe = pd.read_csv(\"./ebe_gender_data_selection.csv\")\n",
    "\n",
    "validate_data(gender_ebe)\n",
    "\n",
    "gender_ebe.to_csv(\"./ebe_gender_data_selection.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pd.read_csv(\"./ebe_gender_data_selection.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selected'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[df['selected']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Religion EBE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to filter out the sentences that does not make any sense semantically and select those sentences that can be generalized for both genders. We check only the pair sentences (the sentences where the subject from natural sentences is replaced by opposing gender entity). We use Chatgpt-3.5 for this purpose. One can change the explicitReligion selection inside the code to be muslim as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "system_prompt = '''You are an assistant. Your job is to determine whether a given prompt is semantically correct and does not \n",
    "contradict nature of a Muslim religion, like idol worshipping or Hindu name or wrong religious norm or wrong religious book etc. Respond with 1 for yes and 0 for no and provide no other extra answer.'''\n",
    "\n",
    "def sanitize_log_name(filename):\n",
    "    return filename.replace(\" \", \"_\").replace(\":\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "def create_message(text, pair):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.replace(\"\\n\", \" \")},\n",
    "        {\"role\": \"user\", \"content\": f\"Text: {pair}\"}\n",
    "    ]\n",
    "\n",
    "def validate_data(df):\n",
    "    count = 0\n",
    "\n",
    "    f = open(sanitize_log_name(f\"./logs/data_generation_{datetime.now()}.log\"), \"w\")\n",
    "    f.write(\"RELIGION\\n\\n\")\n",
    "    for index, row in df.iterrows():\n",
    "        if row['selected'] != -2:\n",
    "            continue\n",
    "        if row[\"explicitReligion\"] != 'hindu':\n",
    "            continue\n",
    "        text = row[\"text\"]\n",
    "        pair = row['pair']\n",
    "        if len(pair.split()) < 6: \n",
    "            print(f\"Index: {index}, sentence: {pair}, content: {0} -> too short\")\n",
    "            f.write(f\"Index: {index}, sentence: {pair}, content: {0} -> too short\\n\")\n",
    "            df.at[index, 'selected'] = 0\n",
    "            continue\n",
    "        model_message = create_message(text, pair)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model_name, messages=model_message, temperature=0.1\n",
    "        )\n",
    "\n",
    "        content = completion.choices[0].message.content\n",
    "        print(f\"Index: {row['ID']}, sentence: {pair}, content: {content}\")\n",
    "        f.write(f\"Index: {row['ID']}, sentence: {pair}, content: {content}\\n\")\n",
    "        if content == \"0\" or content == \"no\":\n",
    "            df.at[index, 'selected'] = 0\n",
    "        elif content == \"1\" or content == \"yes\":\n",
    "            df.at[index, 'selected'] = 1\n",
    "        else:\n",
    "            df.at[index, 'selected'] = -1\n",
    "            print(f\"Error at index: {row['ID']}\")\n",
    "            f.write(f\"Error at index: {row['ID']}\\n\")\n",
    "\n",
    "        count += 1\n",
    "        if count == 1000:\n",
    "            break\n",
    "\n",
    "        if count % 20 == 0 and count > 1:\n",
    "            df.to_csv(\"./ebe_religion_selection.csv\", index=False) \n",
    "\n",
    "religion_ebe = pd.read_csv(\"./ebe_religion_selection.csv\")\n",
    "\n",
    "validate_data(religion_ebe)\n",
    "\n",
    "religion_ebe.to_csv(\"./ebe_religion_selection.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_ebe = pd.read_csv(\"./ebe_religion_selection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_ebe['explicitReligion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = religion_ebe.sample(frac = 0.2)\n",
    "df[\"explicitReligion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the fraction to sample\n",
    "frac = 0.18\n",
    "\n",
    "# Calculate the number of samples needed\n",
    "total_samples = int(len(religion_ebe) * frac)\n",
    "samples_per_class = total_samples // religion_ebe['explicitReligion'].nunique()\n",
    "\n",
    "# Group by the 'explicitReligion' column and sample\n",
    "balanced_df = religion_ebe.groupby('explicitReligion').apply(lambda x: x.sample(samples_per_class))\n",
    "\n",
    "print(\"Balanced Sampled DataFrame:\")\n",
    "print(balanced_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df['explicitReligion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.to_csv(\"./ebe_religion_data_selection.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv(\"/home/jayanta/Documents/CodeReviewAnnotationProject/DataProcessor/ebe_religion_data_selection.csv\")\n",
    "\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df = balanced_df[~balanced_df['text'].str.contains(\"দেবী\")]\n",
    "\n",
    "len(refined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df = refined_df[~refined_df['text'].str.contains(\"ঈদ\")]\n",
    "\n",
    "len(refined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df.to_csv(\"./ebe_religion_data_selection.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
